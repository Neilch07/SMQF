"""
å›æµ‹ç­–ç•¥æ¨¡å— - åŸºäºæ¨¡å‹é¢„æµ‹ç”Ÿæˆäº¤æ˜“ä»“ä½å¹¶è®¡ç®—ç»©æ•ˆ

âš ï¸ æ—¶åºé€»è¾‘è¯´æ˜ï¼ˆæ— æœªæ¥ä¿¡æ¯æ³„éœ²ï¼‰ï¼š
1. t æ—¥æ”¶ç›˜å‰ï¼šè·å¾—å› å­å€¼ï¼Œç”Ÿæˆé¢„æµ‹ä¿¡å· pred(t)
2. t+1 æ—¥å¼€ç›˜ï¼šæ ¹æ® pred(t) æ„å»ºä»“ä½ï¼ˆåšå¤š/åšç©ºï¼‰
3. t+1 æ—¥æ”¶ç›˜ï¼šä»“ä½ç»“ç®—ï¼Œè·å¾— ret(t+1) æ”¶ç›Š
4. é‡å¤ä»¥ä¸Šæ­¥éª¤

ä¸åŒæ ‡ç­¾ç±»å‹çš„äº¤æ˜“ç­–ç•¥ï¼š
- cumulative: é¢„æµ‹ [t+1, t+h]ï¼Œåœ¨ t+1 å»ºä»“ï¼Œt+h å¹³ä»“
- ret#2: é¢„æµ‹ t+2/t+1ï¼Œåœ¨ t+1 å»ºä»“ï¼ˆå› ä¸ºéœ€è¦è§‚å¯Ÿ t+1 æ”¶ç›Šä½œä¸ºåŸºå‡†ï¼‰
- ret#5: é¢„æµ‹ t+5/t+1ï¼Œåœ¨ t+1 å»ºä»“
- ret#20: é¢„æµ‹ t+20/t+1ï¼Œåœ¨ t+1 å»ºä»“
"""

import os
import json
import argparse
from typing import Dict, Tuple, Optional
import numpy as np
import pandas as pd
import warnings

warnings.filterwarnings("ignore")


def load_predictions(preds_path: str) -> pd.DataFrame:
	"""åŠ è½½æ¨¡å‹é¢„æµ‹ç»“æœ
	
	Args:
		preds_path: é¢„æµ‹æ–‡ä»¶è·¯å¾„ï¼ˆparquet æˆ– csvï¼‰
		
	Returns:
		åŒ…å« pred å’Œ y åˆ—çš„ DataFrameï¼Œç´¢å¼•ä¸º (date, ticker)
	"""
	if preds_path.endswith('.parquet'):
		df = pd.read_parquet(preds_path)
	elif preds_path.endswith('.csv'):
		df = pd.read_csv(preds_path, index_col=[0, 1], parse_dates=[0])
	else:
		raise ValueError(f"Unsupported file format: {preds_path}")
	
	# ç¡®ä¿ç´¢å¼•æ˜¯ MultiIndex (date, ticker)
	if not isinstance(df.index, pd.MultiIndex):
		raise ValueError("Prediction file must have MultiIndex (date, ticker)")
	
	return df


def generate_positions(
	df_preds: pd.DataFrame,
	long_quantile: float = 0.2,
	short_quantile: float = 0.2,
	method: str = "equal_weight",
) -> pd.DataFrame:
	"""æ ¹æ®é¢„æµ‹å€¼ç”Ÿæˆäº¤æ˜“ä»“ä½ï¼ˆæ— æœªæ¥ä¿¡æ¯ï¼‰
	
	âš ï¸ æ—¶åºé€»è¾‘ï¼š
	- t æ—¥çš„é¢„æµ‹å€¼ pred(t) â†’ t+1 æ—¥çš„ä»“ä½ position(t+1)
	- position > 0: åšå¤š
	- position < 0: åšç©º
	- position = 0: ä¸æŒä»“
	
	Args:
		df_preds: é¢„æµ‹æ•°æ®ï¼ŒåŒ…å« pred åˆ—ï¼Œç´¢å¼•ä¸º (date, ticker)
		long_quantile: åšå¤šåˆ†ä½æ•°ï¼ˆtop x%ï¼‰
		short_quantile: åšç©ºåˆ†ä½æ•°ï¼ˆbottom x%ï¼‰
		method: ä»“ä½åˆ†é…æ–¹æ³•
			- "equal_weight": ç­‰æƒé‡
			- "pred_weight": æŒ‰é¢„æµ‹å€¼åŠ æƒ
	
	Returns:
		ä»“ä½ DataFrameï¼Œç´¢å¼•ä¸º (date, ticker)ï¼Œåˆ—ä¸º position
	"""
	positions = []
	dates = []
	tickers_list = []
	
	# æŒ‰æ—¥æœŸåˆ†ç»„ç”Ÿæˆä»“ä½
	for date, group in df_preds.groupby(level=0):
		if len(group) < 20:  # æ ·æœ¬å¤ªå°‘è·³è¿‡
			continue
		
		# è®¡ç®—é¢„æµ‹å€¼çš„åˆ†ä½æ•°æ’å
		pred_ranks = group["pred"].rank(pct=True)
		
		# åšå¤šæ ‡çš„ï¼šé¢„æµ‹æ”¶ç›Šæœ€é«˜çš„ top quantile
		long_mask = pred_ranks >= (1 - long_quantile)
		# åšç©ºæ ‡çš„ï¼šé¢„æµ‹æ”¶ç›Šæœ€ä½çš„ bottom quantile
		short_mask = pred_ranks <= short_quantile
		
		# è®¡ç®—ä»“ä½æƒé‡
		if method == "equal_weight":
			# ç­‰æƒé‡ï¼šå¤šå¤´å¹³å‡åˆ†é… +1ï¼Œç©ºå¤´å¹³å‡åˆ†é… -1
			n_long = long_mask.sum()
			n_short = short_mask.sum()
			
			position = pd.Series(0.0, index=group.index)
			if n_long > 0:
				position[long_mask] = 1.0 / n_long
			if n_short > 0:
				position[short_mask] = -1.0 / n_short
		
		elif method == "pred_weight":
			# æŒ‰é¢„æµ‹å€¼åŠ æƒ
			pred_values = group["pred"]
			
			# å¤šå¤´æƒé‡ï¼šå½’ä¸€åŒ–åçš„é¢„æµ‹å€¼
			if long_mask.sum() > 0:
				long_weights = pred_values[long_mask]
				long_weights = long_weights / long_weights.sum()
			else:
				long_weights = pd.Series(dtype=float)
			
			# ç©ºå¤´æƒé‡ï¼šå½’ä¸€åŒ–åçš„è´Ÿé¢„æµ‹å€¼
			if short_mask.sum() > 0:
				short_weights = -pred_values[short_mask]
				short_weights = short_weights / short_weights.sum()
			else:
				short_weights = pd.Series(dtype=float)
			
			position = pd.Series(0.0, index=group.index)
			position[long_mask] = long_weights
			position[short_mask] = -short_weights
		
		else:
			raise ValueError(f"Unknown method: {method}")
		
		positions.extend(position.values)
		dates.extend([date] * len(group))
		tickers_list.extend(group.index.get_level_values(1).tolist())
	
	# æ„å»º DataFrame
	df_positions = pd.DataFrame({
		"position": positions
	}, index=pd.MultiIndex.from_arrays([dates, tickers_list], names=["date", "ticker"]))
	
	return df_positions


def compute_strategy_returns(
	df_preds: pd.DataFrame,
	df_positions: pd.DataFrame,
	label_type: str = "cumulative",
	horizon: int = 5,
	df_raw_returns: Optional[pd.DataFrame] = None,
) -> pd.DataFrame:
	"""è®¡ç®—ç­–ç•¥æ”¶ç›Šï¼ˆè€ƒè™‘æ—¶åºæ­£ç¡®æ€§ï¼‰
	
	âš ï¸ æ—¶åºé€»è¾‘ï¼ˆå…³é”® - æ— æœªæ¥ä¿¡æ¯ï¼‰ï¼š
	1. t æ—¥é¢„æµ‹å€¼ pred(t) â†’ ç”Ÿæˆ t æ—¥ä¿¡å·
	2. t+1 æ—¥å¼€ç›˜å»ºä»“ â†’ è·å¾— t+1 æ—¥æ”¶ç›Š
	
	ä¸åŒæ ‡ç­¾ç±»å‹çš„å¤„ç†ï¼š
	   
	ã€cumulative æ ‡ç­¾ã€‘ï¼š
	- é¢„æµ‹ [t+1, t+h] ç´¯è®¡æ”¶ç›Š
	- t+1 å»ºä»“ï¼ŒæŒæœ‰åˆ° t+h
	- ç­–ç•¥æ”¶ç›Š = position(t) Ã— y(t)ï¼Œå…¶ä¸­ y(t) æ˜¯ [t+1, t+h] ç´¯è®¡æ”¶ç›Š
	   
	ã€ret#N æ ‡ç­¾ã€‘ï¼ˆN=2,5,20ï¼‰ï¼š
	- é¢„æµ‹ t+N / t+1 çš„æ¯”ç‡
	- âš ï¸ å…³é”®ï¼šæˆ‘ä»¬åœ¨ t æ—¥åªæœ‰é¢„æµ‹ä¿¡å·ï¼Œåœ¨ t+1 å¼€ç›˜å»ºä»“
	- ç­–ç•¥æ”¶ç›Š = position(t) Ã— ret(t+1)
	- æ³¨æ„ï¼šy åˆ—å­˜å‚¨çš„æ˜¯ ret(t+N)/ret(t+1)ï¼Œä¸èƒ½ç›´æ¥ç”¨ä½œæ”¶ç›Š
	- éœ€è¦ä½¿ç”¨åŸå§‹å•æœŸæ”¶ç›Š ret(t+1)
	
	Args:
		df_preds: é¢„æµ‹æ•°æ®ï¼ŒåŒ…å« y åˆ—ï¼ˆå®é™…æ”¶ç›Šæ ‡ç­¾ï¼‰
		df_positions: ä»“ä½æ•°æ®ï¼Œç´¢å¼•å¯¹åº”ä¿¡å·ç”Ÿæˆæ—¥æœŸ t
		label_type: æ ‡ç­¾ç±»å‹
		horizon: æŒä»“å‘¨æœŸï¼ˆä»…ç”¨äº cumulativeï¼‰
		df_raw_returns: åŸå§‹å•æœŸæ”¶ç›Šæ•°æ® (date x ticker)ï¼Œç”¨äº ret#N æ ‡ç­¾
	
	Returns:
		ç­–ç•¥æ”¶ç›Š DataFrameï¼ŒåŒ…å« strategy_return åˆ—
	"""
	# åˆå¹¶é¢„æµ‹å’Œä»“ä½
	df_combined = df_preds.join(df_positions, how="inner")
	
	if label_type == "cumulative":
		# ç´¯è®¡æ”¶ç›Šæ ‡ç­¾ï¼šç›´æ¥ä½¿ç”¨æ ‡ç­¾æ”¶ç›Š
		# y åˆ—å·²ç»æ˜¯ [t+1, t+h] çš„ç´¯è®¡æ”¶ç›Š
		# position(t) Ã— y(t) = position(t) Ã— ret[t+1:t+h]
		df_combined["strategy_return"] = df_combined["position"] * df_combined["y"]
		
	elif label_type.startswith("ret#"):
		# ret#N æ ‡ç­¾ï¼šéœ€è¦ä½¿ç”¨å•æœŸæ”¶ç›Š
		# y åˆ—æ˜¯ ret(t+N) / ret(t+1)ï¼Œä¸èƒ½ç›´æ¥ç”¨
		
		if df_raw_returns is not None:
			# ä½¿ç”¨åŸå§‹æ”¶ç›Šæ•°æ®
			# å°† raw_returns (date x ticker) è½¬ä¸º long format
			ret_long = df_raw_returns.stack()
			ret_long.index.names = ['date', 'ticker']
			ret_long.name = 'raw_return'
			
			# å¯¹äº position(t)ï¼Œå®é™…æ”¶ç›Šæ˜¯ ret(t+1)
			# éœ€è¦å°† position çš„æ—¥æœŸ shift(-1) æ¥åŒ¹é…æ”¶ç›Š
			df_combined_with_ret = df_combined.join(ret_long, how='inner')
			
			# âš ï¸ æ—¶åºå¯¹é½ï¼šposition(t) å¯¹åº” t æ—¥ä¿¡å·ï¼Œåœ¨ t+1 æ‰§è¡Œ
			# æˆ‘ä»¬éœ€è¦è·å– t+1 æ—¥çš„æ”¶ç›Š
			# æ–¹æ³•ï¼šæŒ‰ ticker åˆ†ç»„ï¼Œå°† position å‘å shift
			def align_position_return(group):
				# group æ˜¯åŒä¸€ ticker çš„æ—¶é—´åºåˆ—
				# position(t) å¯¹åº”çš„æ˜¯ ret(t+1)
				# å› æ­¤ position éœ€è¦ shift(1) æ¥å¯¹é½æœªæ¥æ”¶ç›Š
				group['aligned_position'] = group['position'].shift(1)
				return group
			
			# æŒ‰ ticker åˆ†ç»„å¤„ç†
			df_aligned = df_combined_with_ret.groupby(level=1).apply(align_position_return)
			
			# è®¡ç®—ç­–ç•¥æ”¶ç›Š = aligned_position Ã— raw_return
			df_aligned["strategy_return"] = df_aligned["aligned_position"] * df_aligned["raw_return"]
			
			# å»é™¤ NaNï¼ˆç¬¬ä¸€å¤©æ²¡æœ‰å‰ä¸€å¤©çš„ positionï¼‰
			df_combined = df_aligned.dropna(subset=['strategy_return'])
			
			print(f"[info] Using raw returns for {label_type} backtest (time-aligned)")
		else:
			# æ²¡æœ‰åŸå§‹æ”¶ç›Šæ•°æ®ï¼Œä½¿ç”¨ç®€åŒ–æ–¹æ³•
			# è­¦å‘Šï¼šè¿™å¯èƒ½ä¸å‡†ç¡®
			df_combined["strategy_return"] = df_combined["position"] * df_combined["y"]
			print(f"[warn] No raw returns provided. Using label value as proxy for {label_type}. "
				  f"Results may be inaccurate!")
	
	else:
		raise ValueError(f"Unknown label_type: {label_type}")
	
	return df_combined


def compute_performance_metrics(
	df_strategy: pd.DataFrame,
	annual_factor: int = 243,
) -> Dict[str, float]:
	"""è®¡ç®—ç­–ç•¥ç»©æ•ˆæŒ‡æ ‡
	
	Args:
		df_strategy: ç­–ç•¥æ”¶ç›Šæ•°æ®ï¼ŒåŒ…å« strategy_return åˆ—
		annual_factor: å¹´åŒ–å› å­ï¼ˆäº¤æ˜“æ—¥æ•°ï¼‰
	
	Returns:
		ç»©æ•ˆæŒ‡æ ‡å­—å…¸
	"""
	# æŒ‰æ—¥æœŸèšåˆæ”¶ç›Šï¼ˆå¤šåªè‚¡ç¥¨çš„ç»„åˆæ”¶ç›Šï¼‰
	daily_returns = df_strategy.groupby(level=0)["strategy_return"].sum()
	
	# åŸºæœ¬ç»Ÿè®¡
	n_days = len(daily_returns)
	mean_daily = daily_returns.mean()
	std_daily = daily_returns.std()
	
	# å¹´åŒ–æŒ‡æ ‡
	annual_return = mean_daily * annual_factor
	annual_vol = std_daily * np.sqrt(annual_factor)
	sharpe_ratio = annual_return / annual_vol if annual_vol > 0 else np.nan
	
	# ç´¯è®¡æ”¶ç›Š
	cumulative_return = (1 + daily_returns).cumprod().iloc[-1] - 1 if n_days > 0 else 0
	
	# æœ€å¤§å›æ’¤
	cum_rets = (1 + daily_returns).cumprod()
	running_max = cum_rets.expanding().max()
	drawdown = (cum_rets - running_max) / running_max
	max_drawdown = drawdown.min()
	
	# èƒœç‡
	win_rate = (daily_returns > 0).sum() / n_days if n_days > 0 else 0
	
	# ç›ˆäºæ¯”
	avg_win = daily_returns[daily_returns > 0].mean() if (daily_returns > 0).any() else 0
	avg_loss = daily_returns[daily_returns < 0].mean() if (daily_returns < 0).any() else 0
	profit_loss_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else np.nan
	
	# Calmar æ¯”ç‡
	calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown != 0 else np.nan
	
	metrics = {
		"n_days": n_days,
		"cumulative_return": float(cumulative_return),
		"annual_return": float(annual_return),
		"annual_volatility": float(annual_vol),
		"sharpe_ratio": float(sharpe_ratio),
		"max_drawdown": float(max_drawdown),
		"calmar_ratio": float(calmar_ratio),
		"win_rate": float(win_rate),
		"avg_daily_return": float(mean_daily),
		"profit_loss_ratio": float(profit_loss_ratio),
	}
	
	return metrics


def plot_strategy_performance(
	df_strategy: pd.DataFrame,
	save_path: Optional[str] = None,
	title: str = "Strategy Performance",
):
	"""ç»˜åˆ¶ç­–ç•¥è¡¨ç°å›¾
	
	Args:
		df_strategy: ç­–ç•¥æ”¶ç›Šæ•°æ®
		save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
		title: å›¾è¡¨æ ‡é¢˜
	"""
	try:
		import matplotlib.pyplot as plt
		import matplotlib.dates as mdates
	except ImportError:
		print("[warn] matplotlib not installed, skipping plots")
		return
	
	# æŒ‰æ—¥æœŸèšåˆæ”¶ç›Š
	daily_returns = df_strategy.groupby(level=0)["strategy_return"].sum()
	
	# è®¡ç®—ç´¯è®¡å‡€å€¼
	cumulative_nav = (1 + daily_returns).cumprod()
	
	# åˆ›å»ºå­å›¾
	fig, axes = plt.subplots(3, 1, figsize=(14, 10))
	
	# 1. å‡€å€¼æ›²çº¿
	ax1 = axes[0]
	ax1.plot(cumulative_nav.index, cumulative_nav.values, linewidth=2, color='#1f77b4')
	ax1.set_ylabel('Cumulative NAV', fontsize=11)
	ax1.set_title(title, fontsize=13, fontweight='bold')
	ax1.grid(True, alpha=0.3)
	ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
	
	# 2. æ¯æ—¥æ”¶ç›Š
	ax2 = axes[1]
	colors = ['g' if r > 0 else 'r' for r in daily_returns]
	ax2.bar(daily_returns.index, daily_returns.values, color=colors, alpha=0.6, width=1)
	ax2.set_ylabel('Daily Return', fontsize=11)
	ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)
	ax2.grid(True, alpha=0.3)
	ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
	
	# 3. å›æ’¤
	ax3 = axes[2]
	cum_rets = (1 + daily_returns).cumprod()
	running_max = cum_rets.expanding().max()
	drawdown = (cum_rets - running_max) / running_max
	ax3.fill_between(drawdown.index, drawdown.values, 0, color='red', alpha=0.3)
	ax3.set_ylabel('Drawdown', fontsize=11)
	ax3.set_xlabel('Date', fontsize=11)
	ax3.grid(True, alpha=0.3)
	ax3.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
	
	# æ ¼å¼åŒ– x è½´
	for ax in axes:
		ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
		plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
	
	plt.tight_layout()
	
	if save_path:
		os.makedirs(os.path.dirname(save_path), exist_ok=True)
		plt.savefig(save_path, dpi=300, bbox_inches='tight')
		print(f"ğŸ“Š Strategy performance plot saved to: {save_path}")
		plt.close()
	else:
		plt.show()


def main():
	parser = argparse.ArgumentParser(description="Backtest strategy based on model predictions")
	parser.add_argument("--run-dir", type=str, required=True, help="Run directory containing predictions")
	parser.add_argument("--preds-file", type=str, default="test_preds.parquet", help="Prediction file name")
	parser.add_argument("--long-quantile", type=float, default=0.2, help="Long position quantile (top x%)")
	parser.add_argument("--short-quantile", type=float, default=0.2, help="Short position quantile (bottom x%)")
	parser.add_argument("--method", type=str, default="equal_weight", 
						choices=["equal_weight", "pred_weight"], help="Position weighting method")
	parser.add_argument("--returns-file", type=str, default=None, 
						help="Path to raw returns file (required for ret#N labels)")
	parser.add_argument("--output-name", type=str, default=None, help="Output file prefix (default: auto)")
	
	args = parser.parse_args()
	
	# åŠ è½½ run é…ç½®
	config_path = os.path.join(args.run_dir, "run_config.json")
	if os.path.exists(config_path):
		with open(config_path, "r", encoding="utf-8") as f:
			run_config = json.load(f)
		label_type = run_config.get("label_type", "cumulative")
		label_name = run_config.get("label_name", "unknown")
		horizon = run_config.get("horizon", 5)
		print(f"[info] Loaded config: label={label_name}, horizon={horizon}")
	else:
		print("[warn] No run_config.json found, using defaults")
		label_type = "cumulative"
		label_name = "unknown"
		horizon = 5
	
	# åŠ è½½é¢„æµ‹æ•°æ®
	preds_path = os.path.join(args.run_dir, args.preds_file)
	if not os.path.exists(preds_path):
		raise FileNotFoundError(f"Predictions file not found: {preds_path}")
	
	print(f"[info] Loading predictions from: {preds_path}")
	df_preds = load_predictions(preds_path)
	print(f"[info] Loaded {len(df_preds)} prediction samples")
	
	# åŠ è½½åŸå§‹æ”¶ç›Šæ•°æ®ï¼ˆç”¨äº ret#N æ ‡ç­¾ï¼‰
	df_raw_returns = None
	if label_type.startswith("ret#"):
		if args.returns_file:
			print(f"[info] Loading raw returns from: {args.returns_file}")
			if args.returns_file.endswith('.parquet'):
				df_raw_returns = pd.read_parquet(args.returns_file)
			elif args.returns_file.endswith('.csv'):
				df_raw_returns = pd.read_csv(args.returns_file, index_col=0, parse_dates=True)
			print(f"[info] Loaded raw returns: {df_raw_returns.shape}")
		else:
			print(f"[warn] No --returns-file provided for {label_type}. Using approximate method.")
	
	# ç”Ÿæˆä»“ä½
	print(f"[info] Generating positions (long={args.long_quantile}, short={args.short_quantile}, method={args.method})...")
	df_positions = generate_positions(
		df_preds,
		long_quantile=args.long_quantile,
		short_quantile=args.short_quantile,
		method=args.method,
	)
	print(f"[info] Generated {len(df_positions)} positions")
	
	# è®¡ç®—ç­–ç•¥æ”¶ç›Š
	print("[info] Computing strategy returns...")
	df_strategy = compute_strategy_returns(
		df_preds,
		df_positions,
		label_type=label_type,
		horizon=horizon,
		df_raw_returns=df_raw_returns,
	)
	
	# è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
	print("[info] Computing performance metrics...")
	metrics = compute_performance_metrics(df_strategy)
	
	# æ‰“å°ç»“æœ
	print("\n" + "="*60)
	print("ğŸ“Š STRATEGY PERFORMANCE METRICS")
	print("="*60)
	for k, v in metrics.items():
		if isinstance(v, float):
			print(f"{k:25s}: {v:12.4f}")
		else:
			print(f"{k:25s}: {v:12}")
	print("="*60 + "\n")
	
	# ä¿å­˜ç»“æœ
	output_prefix = args.output_name or f"backtest_{args.method}"
	
	# ä¿å­˜æŒ‡æ ‡
	metrics_path = os.path.join(args.run_dir, f"{output_prefix}_metrics.json")
	with open(metrics_path, "w", encoding="utf-8") as f:
		json.dump(metrics, f, ensure_ascii=False, indent=2)
	print(f"âœ… Metrics saved to: {metrics_path}")
	
	# ä¿å­˜ä»“ä½æ•°æ®
	positions_path = os.path.join(args.run_dir, f"{output_prefix}_positions.parquet")
	df_positions.to_parquet(positions_path)
	print(f"âœ… Positions saved to: {positions_path}")
	
	# ä¿å­˜ç­–ç•¥æ”¶ç›Š
	strategy_path = os.path.join(args.run_dir, f"{output_prefix}_returns.parquet")
	df_strategy.to_parquet(strategy_path)
	print(f"âœ… Strategy returns saved to: {strategy_path}")
	
	# ç»˜åˆ¶å›¾è¡¨
	plot_path = os.path.join(args.run_dir, f"{output_prefix}_performance.png")
	plot_strategy_performance(
		df_strategy,
		save_path=plot_path,
		title=f"Strategy Performance - {label_name} ({args.method})",
	)
	
	print(f"\nâœ… All backtest results saved to: {args.run_dir}")


if __name__ == "__main__":
	main()
